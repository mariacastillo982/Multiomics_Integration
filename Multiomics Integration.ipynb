{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646f3b79-08eb-4fb2-bbcf-66a208238666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import networkx as nx\n",
    "from networkx import Graph as NXGraph\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import collections\n",
    "import io\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "from rdflib.extras.external_graph_libs import *\n",
    "from rdflib import Graph, Literal, URIRef, Namespace, XSD, RDF, RDFS\n",
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_graph\n",
    "from rdflib.namespace import RDF, RDFS\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, CSV\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f51c48-4965-4f22-b97a-89aeed669208",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = '''\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "PREFIX vg: <http://biohackathon.org/resource/vg#>\n",
    "PREFIX uniprotkb: <http://purl.uniprot.org/uniprot/>\n",
    "PREFIX uberon: <http://purl.obolibrary.org/obo/uo#>\n",
    "PREFIX taxon: <http://purl.uniprot.org/taxonomy/>\n",
    "PREFIX sp: <http://spinrdf.org/sp#>\n",
    "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "PREFIX sio: <http://semanticscience.org/resource/>\n",
    "PREFIX sh: <http://www.w3.org/ns/shacl#>\n",
    "PREFIX schema: <http://schema.org/>\n",
    "PREFIX sachem: <http://bioinfo.uochb.cas.cz/rdf/v1.0/sachem#>\n",
    "PREFIX rh: <http://rdf.rhea-db.org/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX pubmed: <http://rdf.ncbi.nlm.nih.gov/pubmed/>\n",
    "PREFIX ps: <http://www.wikidata.org/prop/statement/>\n",
    "PREFIX pq: <http://www.wikidata.org/prop/qualifier/>\n",
    "PREFIX patent: <http://data.epo.org/linked-data/def/patent/>\n",
    "PREFIX p: <http://www.wikidata.org/prop/>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX orthodbGroup: <http://purl.orthodb.org/odbgroup/>\n",
    "PREFIX orthodb: <http://purl.orthodb.org/>\n",
    "PREFIX orth: <http://purl.org/net/orth#>\n",
    "PREFIX obo: <http://purl.obolibrary.org/obo/>\n",
    "PREFIX np: <http://nextprot.org/rdf#>\n",
    "PREFIX nextprot: <http://nextprot.org/rdf/entry/>\n",
    "PREFIX mnx: <https://rdf.metanetx.org/schema/>\n",
    "PREFIX mnet: <https://rdf.metanetx.org/mnet/>\n",
    "PREFIX mesh: <http://id.nlm.nih.gov/mesh/>\n",
    "PREFIX lscr: <http://purl.org/lscr#>\n",
    "PREFIX lipidmaps: <https://www.lipidmaps.org/rdf/>\n",
    "PREFIX keywords: <http://purl.uniprot.org/keywords/>\n",
    "PREFIX insdcschema: <http://ddbj.nig.ac.jp/ontologies/nucleotide/>\n",
    "PREFIX insdc: <http://identifiers.org/insdc/>\n",
    "PREFIX identifiers: <http://identifiers.org/>\n",
    "PREFIX glyconnect: <https://purl.org/glyconnect/>\n",
    "PREFIX glycan: <http://purl.jp/bio/12/glyco/glycan#>\n",
    "PREFIX genex: <http://purl.org/genex#>\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "PREFIX eunisSpecies: <http://eunis.eea.europa.eu/rdf/species-schema.rdf#>\n",
    "PREFIX ensembltranscript: <http://rdf.ebi.ac.uk/resource/ensembl.transcript/>\n",
    "PREFIX ensemblterms: <http://rdf.ebi.ac.uk/terms/ensembl/>\n",
    "PREFIX ensemblprotein: <http://rdf.ebi.ac.uk/resource/ensembl.protein/>\n",
    "PREFIX ensemblexon: <http://rdf.ebi.ac.uk/resource/ensembl.exon/>\n",
    "PREFIX ensembl: <http://rdf.ebi.ac.uk/resource/ensembl/>\n",
    "PREFIX ec: <http://purl.uniprot.org/enzyme/>\n",
    "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "PREFIX dc: <http://purl.org/dc/terms/>\n",
    "PREFIX chebislash: <http://purl.obolibrary.org/obo/chebi/>\n",
    "PREFIX chebihash: <http://purl.obolibrary.org/obo/chebi#>\n",
    "PREFIX cco: <http://rdf.ebi.ac.uk/terms/chembl#>\n",
    "PREFIX busco: <http://busco.ezlab.org/schema#>\n",
    "PREFIX bibo: <http://purl.org/ontology/bibo/>\n",
    "PREFIX allie: <http://allie.dbcls.jp/>\n",
    "PREFIX SWISSLIPID: <https://swisslipids.org/rdf/SLM_>\n",
    "PREFIX GO: <http://purl.obolibrary.org/obo/GO_>\n",
    "PREFIX ECO: <http://purl.obolibrary.org/obo/ECO_>\n",
    "PREFIX CHEBI: <http://purl.obolibrary.org/obo/CHEBI_>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX up: <http://purl.uniprot.org/core/>\n",
    "PREFIX faldo: <http://biohackathon.org/resource/faldo#>\n",
    "'''\n",
    "\n",
    "query = '''\n",
    "SELECT ?protein ?transcript ?ensprotein ?gene\n",
    "WHERE\n",
    "{\n",
    "  ?protein rdfs:seeAlso ?transcript .\n",
    "  ?protein a up:Protein .\n",
    "  ?protein up:reviewed true .\n",
    "  ?protein up:organism taxon:9606 .\n",
    "  ?transcript a up:Transcript_Resource .\n",
    "  ?transcript up:translatedTo ?ensprotein .\n",
    "  ?transcript up:transcribedFrom ?gene .\n",
    "}\n",
    "'''\n",
    "\n",
    "q=f'''\n",
    "{prefixes}\n",
    "{query}\n",
    "'''\n",
    "\n",
    "\n",
    "class KnowledgeGraph():\n",
    "    def __init__(self, sparql_endpoint='http://sparql.uniprot.org/sparql'):\n",
    "        self.sparql_endpoint = sparql_endpoint\n",
    "    def query_sparql(self, q, output_format='json'):\n",
    "        sparql = SPARQLWrapper(self.sparql_endpoint)\n",
    "        sparql.setQuery(q)\n",
    "        sparql.setReturnFormat(output_format)\n",
    "        results = sparql.query()\n",
    "        res = results.convert()\n",
    "        return res\n",
    "    def query_to_pandas(self, q):\n",
    "        res = self.query_sparql(q, output_format='csv')\n",
    "        df = pd.read_csv(io.BytesIO(res), sep=\",\")\n",
    "        return df\n",
    "    def query_to_graph(self, q):\n",
    "        res = self.query_sparql(q, output_format='json')  # Change the output_format to 'json'\n",
    "        # RDF graph setup\n",
    "        rdf_graph = Graph()\n",
    "        ens_namespace = Namespace(\"http://rdf.ebi.ac.uk/resource/ensembl/\")\n",
    "        transcript_namespace = Namespace(\"http://rdf.ebi.ac.uk/resource/ensembl.transcript/\")\n",
    "        protein_namespace = Namespace(\"http://rdf.ebi.ac.uk/resource/ensembl.protein/\")\n",
    "        uniprot_namespace = Namespace(\"http://purl.uniprot.org/uniprot/\")\n",
    "\n",
    "        rdf_graph.bind('ens', ens_namespace)\n",
    "        rdf_graph.bind('transcript', transcript_namespace)\n",
    "        rdf_graph.bind('protein', protein_namespace)\n",
    "        rdf_graph.bind('uniprot', uniprot_namespace)\n",
    "\n",
    "        # Process bindings\n",
    "        for binding in res[\"results\"][\"bindings\"]:\n",
    "            transcript_uri = URIRef(binding[\"transcript\"][\"value\"])\n",
    "            ensprotein_uri = URIRef(binding[\"ensprotein\"][\"value\"])\n",
    "            gene_uri = URIRef(binding[\"gene\"][\"value\"].rsplit('.', 1)[0])\n",
    "            protein_uri = URIRef(binding[\"protein\"][\"value\"])\n",
    "\n",
    "            rdf_graph.add((transcript_uri, RDF.type, transcript_namespace.Transcript))\n",
    "            rdf_graph.add((ensprotein_uri, RDF.type, protein_namespace.Protein))\n",
    "            rdf_graph.add((gene_uri, RDF.type, ens_namespace.Gene))\n",
    "            rdf_graph.add((protein_uri, RDF.type, uniprot_namespace.Protein))\n",
    "\n",
    "            rdf_graph.add((transcript_uri, transcript_namespace.translateTo, ensprotein_uri))\n",
    "            rdf_graph.add((gene_uri, ens_namespace.transcribeTo, transcript_uri))\n",
    "            rdf_graph.add((ensprotein_uri, protein_namespace.isEquivalentTo, protein_uri))\n",
    "        # Print or serialize the RDF graph\n",
    "        rdf_graph.serialize(destination='/content/drive/MyDrive/KAUST Master/Research/Heatstroke/r.ttl', format='turtle')\n",
    "        return rdf_graph\n",
    "    \n",
    "    \n",
    "#Integrate Knowledge graph with miRNAs\n",
    "def Knowledge_mirna(r,miRNA_DB, knowledge_graph):\n",
    "    miRNA_DB['gene'] = miRNA_DB['gene'].apply(add_prefix_en)\n",
    "    r['gene'] = r['gene'].apply(gene_mod)\n",
    "    merged_df_mirna_trans = pd.merge(r, miRNA_DB, on='gene', how='left')\n",
    "    merged_df_mirna_trans['miRNA'] = merged_df_mirna_trans['miRNA'].apply(add_prefix_miRNA)\n",
    "\n",
    "    mirna_namespace = Namespace(\"http://rdf.ebi.ac.uk/resource/ensembl.miRNA/\")\n",
    "    knowledge_graph.bind('mirna', mirna_namespace)\n",
    "    for index, row in merged_df_mirna_trans.iterrows():\n",
    "        if pd.notna(row['miRNA']) and  pd.notna(row['transcript']):\n",
    "            subject = URIRef(row['miRNA'])\n",
    "            obj = URIRef(row['transcript'])\n",
    "            knowledge_graph.add((subject, RDF.type, mirna_namespace.Gene))\n",
    "            knowledge_graph.add((subject, mirna_namespace.regulates, obj))\n",
    "    return knowledge_graph\n",
    "\n",
    "#Integrate Knowledge graph with miRNAs return in csv\n",
    "def Knowledge_mirna_csv(r,miRNA_DB):\n",
    "    r['gene'] = r['gene'].apply(remove_urls)\n",
    "    r['gene'] = r['gene'].apply(gene_mod)\n",
    "    merged_df_mirna_trans = pd.merge(r, miRNA_DB, on='gene', how='left')\n",
    "    merged_df_mirna_trans['gene'] = merged_df_mirna_trans['gene'].apply(add_prefix_en)\n",
    "    merged_df_mirna_trans['miRNA'] = merged_df_mirna_trans['miRNA'].apply(add_prefix_miRNA)\n",
    "    merged_df_mirna_trans.rename(columns={'miRNA':'mirna'}, inplace=True)\n",
    "    return merged_df_mirna_trans\n",
    "\n",
    "def convert_miRNA_list(mirna_list):\n",
    "    new_list = [miRNA.split('-5p')[0].split('-3p')[0] if '-5p' in miRNA else\n",
    "                (miRNA.split('-3p')[0] if '-3p' in miRNA else miRNA) for miRNA in mirna_list]\n",
    "    return new_list\n",
    "\n",
    "def add_prefix_en(value):\n",
    "    if pd.notna(value):\n",
    "        return 'http://rdf.ebi.ac.uk/resource/ensembl/' + str(value)\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def add_prefix_t(value):\n",
    "    if pd.notna(value):  # Check if value is not NaN\n",
    "        return 'http://rdf.ebi.ac.uk/resource/ensembl.transcript/' + str(value)\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def add_prefix_uni(value):\n",
    "    if pd.notna(value):  # Check if value is not NaN\n",
    "        return 'http://purl.uniprot.org/uniprot/' + str(value)\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def add_prefix_miRNA(value):\n",
    "    if pd.notna(value):  # Check if value is not NaN\n",
    "        return 'http://rdf.ebi.ac.uk/resource/ensembl.miRNA/' + str(value)\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def gene_mod(value):\n",
    "       return value.rsplit('.', 1)[0]\n",
    "\n",
    "def get_uuid(df, file_name, col_name):\n",
    "    # Filter DataFrame based on file_name\n",
    "    result_df = df[df['file_name'] == file_name]\n",
    "    # Check if any matching rows are found\n",
    "    if not result_df.empty:\n",
    "        # Extract and return the UUID\n",
    "        return result_df[col_name].iloc[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def map_proteins(prot_db, prot_table):\n",
    "    prot = pd.merge(prot_table, prot_db, on='AGID', how='left')\n",
    "    prot = prot[['protein','protein_expression']]\n",
    "    prot = prot.dropna(subset=['protein_expression'])\n",
    "    prot = prot.drop_duplicates(subset=['protein'])\n",
    "    prot.rename(columns={\"gene_id\": \"gene\"}, inplace=True)\n",
    "    return prot\n",
    "\n",
    "def process_strings(input_list):\n",
    "    processed_list = []\n",
    "    for string in input_list:\n",
    "        if pd.isna(string):\n",
    "            processed_list.append(np.nan)\n",
    "        else:\n",
    "            parts = string.split('-')\n",
    "            result = '-'.join(parts[:3])\n",
    "            processed_list.append(result)\n",
    "    return processed_list\n",
    "\n",
    "def iterate_and_read_files(folder_path, omic, disease, target_extension=None): ###1\n",
    "    omic2=omic+'_expression'\n",
    "    directory_path = os.path.join(folder_path, omic2, disease)\n",
    "    if not os.path.isdir(directory_path):\n",
    "        print(f\"The path '{directory_path}' is not a directory.\")\n",
    "        return\n",
    "    dataframes_dict = {}\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            if target_extension and filename.endswith(target_extension):\n",
    "                if omic2 == 'gene_expression':\n",
    "                    file_content = pd.read_csv(file_path, sep='\\t', skiprows=[0,2,3,4,5])\n",
    "                else:\n",
    "                    file_content = pd.read_csv(file_path, sep='\\t')\n",
    "                dataframes_dict[filename] = file_content   \n",
    "    return dataframes_dict\n",
    "\n",
    "def create_rdf_graph(dataframe, omic, UUID, prot_db):\n",
    "    rdf_graph = Graph()\n",
    "    ns=\"http://rdf.ebi.ac.uk/resource/sample/\"\n",
    "    sample_uri = Namespace(ns)\n",
    "    sample_uri2 = URIRef(ns + UUID)\n",
    "    rdf_graph.add((sample_uri2, RDF.type, URIRef(omic)))\n",
    "    rdf_graph.bind('sample', sample_uri)\n",
    "    rdf_graph.bind('xsd', XSD)\n",
    "    if omic == 'protein_expression':\n",
    "        dataframe= map_proteins(prot_db, dataframe)\n",
    "        uniprot_namespace = Namespace(\"http://purl.uniprot.org/uniprot/\")\n",
    "        rdf_graph.bind('uniprot', uniprot_namespace)\n",
    "        #dataframe['gene_id']=URIRef(add_prefix_en(dataframe['gene_id']))\n",
    "    if omic == 'gene_expression':\n",
    "        dataframe['gene_id'] = dataframe['gene_id'].str.split('/')\n",
    "        ens_namespace = Namespace(\"http://rdf.ebi.ac.uk/resource/ensembl/\")       \n",
    "        rdf_graph.bind('ens', ens_namespace) \n",
    "    if omic == 'mirna_expression':\n",
    "        mirna_namespace = Namespace(\"http://rdf.ebi.ac.uk/resource/ensembl.miRNA/\")\n",
    "        rdf_graph.bind('mirna', mirna_namespace)\n",
    "    #rdf_graph.add((sample_uri, RDF.type, RDFS.Resource))\n",
    "    #rdf_graph.add((custom_ns, custom_ns.hasSample, sample_uri))\n",
    "    for index, row in dataframe.iterrows():\n",
    "        if omic == 'gene_expression':\n",
    "              if pd.notna(row['gene_id']) and  pd.notna(row['tpm_unstranded']):    \n",
    "                subject = URIRef(add_prefix_en(row['gene_id'][0]))\n",
    "                #print(subject)\n",
    "                rdf_graph.add((subject, RDF.type, ens_namespace.Gene))\n",
    "                rdf_graph.add((sample_uri2, ens_namespace.hasGene, subject))\n",
    "                obj = Literal(row['tpm_unstranded'], datatype=XSD.double)\n",
    "                predicate = sample_uri.hasExpression\n",
    "                rdf_graph.add((subject, predicate, obj))\n",
    "        elif omic == 'protein_expression':\n",
    "              if pd.notna(row['protein']) and pd.notna(row[omic]):\n",
    "                subject = URIRef(add_prefix_uni(row['protein']))\n",
    "                rdf_graph.add((subject, RDF.type, uniprot_namespace.Protein))\n",
    "                rdf_graph.add((sample_uri2, uniprot_namespace.hasProtein, subject))\n",
    "                #rdf_graph.add((sample_uri2, URIRef(sample_uri + 'hasProtein'), subject))\n",
    "                obj = Literal(row[omic], datatype=XSD.double)\n",
    "                predicate = sample_uri.hasExpression\n",
    "                rdf_graph.add((subject, predicate, obj))\n",
    "        elif omic == 'mirna_expression':\n",
    "              if pd.notna(row['miRNA_ID']) and pd.notna(row['reads_per_million_miRNA_mapped']):\n",
    "                subject = URIRef(add_prefix_miRNA(row['miRNA_ID']))\n",
    "                rdf_graph.add((subject, RDF.type, mirna_namespace.miRNA))\n",
    "                rdf_graph.add((sample_uri2, mirna_namespace.hasmiRNA, subject))\n",
    "                #rdf_graph.add((sample_uri2, URIRef(sample_uri + 'hasmiRNA'), subject))\n",
    "                obj = Literal(row['reads_per_million_miRNA_mapped'], datatype=XSD.double)\n",
    "                predicate = sample_uri.hasExpression\n",
    "                rdf_graph.add((subject, predicate, obj))               \n",
    "    return rdf_graph\n",
    "\n",
    "def create_rdf_graph_dict(dataframes_dict, df, prot_db):  ####2\n",
    "    #df = pd.read_csv('/encrypted/e3008/Yang_tcga/metadata/metadata.tsv', sep='\\t')\n",
    "    graphs_dict = {}\n",
    "    # Iterate through each item in the dictionary\n",
    "    for filename, dataframe in dataframes_dict.items():\n",
    "        UUID = get_uuid(df, filename, 'submitter_id_x')\n",
    "        omic = get_uuid(df, filename, 'type')       \n",
    "        rdf_graph = create_rdf_graph(dataframe, omic, UUID, prot_db)\n",
    "        #rdf_graph.serialize(destination=f'/home/castilmg/multiomics/output_{omic}_{UUID}.ttl', format='turtle')\n",
    "        graphs_dict[filename] = rdf_graph\n",
    "    return graphs_dict\n",
    "\n",
    "def create_rdf_graph_study(graphs_dict, df, merged_df, disease):  \n",
    "    ns = \"http://rdf.ebi.ac.uk/resource/study/\"\n",
    "    custom_ns = Namespace(ns)\n",
    "    study_uri = URIRef(ns + disease)\n",
    "    rdf_graph = Graph()\n",
    "    rdf_graph.bind('study', ns)\n",
    "    rdf_graph.add((study_uri, RDF.type, custom_ns.Study))\n",
    "    \n",
    "    for filename, graph in graphs_dict.items():\n",
    "        UUID = get_uuid(df, filename, 'submitter_id')\n",
    "        barcode = '-'.join(UUID.split('-')[:3]) \n",
    "        omic = get_uuid(df, filename, 'type') \n",
    "        ns_sample = Namespace(\"http://rdf.ebi.ac.uk/resource/sample/\")\n",
    "        rdf_graph.bind('sample', ns_sample)\n",
    "        sample_uri = URIRef(ns_sample + UUID)\n",
    "        rdf_graph.add((sample_uri, RDF.type, URIRef(omic)))\n",
    "        rdf_graph.add((study_uri, custom_ns.hasSample, sample_uri))\n",
    "        index_of_value = merged_df.index.get_loc(merged_df[merged_df['bcr_patient_barcode'] == barcode].index[0])\n",
    "        row = merged_df.iloc[index_of_value]\n",
    "        gender = row['gender']\n",
    "        age = row['age_at_index']\n",
    "        project = row['project']\n",
    "        #type_c = row['primary_pathology_histological_type']\n",
    "        stage = row['ajcc_pathologic_stage']\n",
    "        #rdf_graph.add((sample_uri, custom_ns.isOmic, Literal(omic)))\n",
    "        if pd.notna(gender):\n",
    "            #rdf_graph.add((sample_uri, URIRef(custom_ns + 'gender'), Literal(gender)))\n",
    "            rdf_graph.add((sample_uri, ns_sample.isGender, Literal(gender)))\n",
    "        if pd.notna(age):\n",
    "            #rdf_graph.add((sample_uri, URIRef(custom_ns + 'age'), Literal(age)))\n",
    "            rdf_graph.add((sample_uri, ns_sample.hasAge, Literal(age)))\n",
    "        if pd.notna(project):\n",
    "            #rdf_graph.add((sample_uri, URIRef(custom_ns + 'projet'), Literal(project)))\n",
    "            rdf_graph.add((sample_uri, ns_sample.isProject, Literal(project)))\n",
    "        #if pd.notna(type_c):\n",
    "            #rdf_graph.add((sample_uri, URIRef(custom_ns + 'type'), Literal(type_c)))\n",
    "        #    rdf_graph.add((sample_uri, ns_sample.isType, Literal(type_c)))\n",
    "        if pd.notna(stage):\n",
    "            #rdf_graph.add((sample_uri, URIRef(custom_ns + 'stage'), Literal(stage)))\n",
    "            rdf_graph.add((sample_uri, ns_sample.isStage, Literal(stage)))\n",
    "    \n",
    "    return rdf_graph\n",
    "\n",
    "def create_sentence(row,omic):\n",
    "    if omic=='protein':\n",
    "        if pd.notna(row['gene']) and pd.notna(row['transcript']):\n",
    "            return f\"The sample {row['Sample']} has protein expression of {row['protein']} with expression level {row['protein_Expression']}, translated from transcript {row['transcript']}, transcribed from gene {row['gene']}.\"\n",
    "        else:\n",
    "            return f\"The sample {row['Sample']} has expression level of protein {row['protein']} with expression level {row['protein_Expression']}.\" \n",
    "    elif omic == 'gene':\n",
    "        if pd.notna(row['protein']) and pd.notna(row['transcript']) and pd.notna(row['mirna']):\n",
    "            return f\"The sample {row['Sample']} has gene expression of {row['gene']} with expression level {row['gene_Expression']}, transcribed to transcript {row['transcript']}, regulated by mirna {row['mirna']}, translated to protein {row['protein']}.\"\n",
    "        else:\n",
    "            return f\"The sample {row['Sample']} has expression level of gene {row['gene']} with expression level {row['gene_Expression']}.\" \n",
    "    elif omic == 'mirna':\n",
    "        if pd.notna(row['gene']) and pd.notna(row['transcript']):\n",
    "            return f\"The sample {row['Sample']} has mirna expression of {row['mirna']} with expression level {row['mirna_Expression']}, that regulates the transcript {row['transcript']} that translates to protein {row['protein']} and is trasncribed from {row['gene']}.\"\n",
    "        else:\n",
    "            return f\"The sample {row['Sample']} has expression level of mirna {row['mirna']} with expression level {row['mirna_Expression']}.\" \n",
    "    elif omic == 'multi2':\n",
    "        if pd.notna(row['gene_Expression']) and pd.notna(row['transcript']) and pd.notna(row['protein_Expression']) and pd.notna(row['mirna_Expression']):\n",
    "            return f\"The sample {row['Sample']} has gene expression of {row['gene']} with expression level {row['gene_Expression']}, transcribed to transcript {row['transcript']}, regulated by mirna {row['mirna']} with expression level {row['mirna_Expression']}, and translated to protein {row['protein']} with expression level {row['protein_Expression']}.\"\n",
    "    elif omic == 'multi':\n",
    "        sentence = \" \"\n",
    "        if pd.notna(row['gene']) and pd.notna(row['gene_Expression']):\n",
    "            s = f\"The sample {row['Sample']} has gene expression of {row['gene']} with expression level {row['gene_Expression']}\"\n",
    "            sentence = sentence + s\n",
    "            if pd.notna(row['transcript']):\n",
    "                s = f\" transcribed to transcript {row['transcript']}\"\n",
    "                sentence = sentence + s \n",
    "            if pd.notna(row['protein']):\n",
    "                s = f\" translated to protein {row['protein']}\" \n",
    "                sentence = sentence + s\n",
    "                if pd.notna(row['protein_Expression']):\n",
    "                    s = f\" with expression level {row['protein_Expression']}\"\n",
    "                    sentence = sentence + s\n",
    "            if pd.notna(row['mirna']): \n",
    "                s = f\" regulated by mirna {row['mirna']}\"\n",
    "                sentence = sentence + s\n",
    "                if pd.notna(row['mirna_Expression']):\n",
    "                    s = f\" with expression level {row['mirna_Expression']}\"\n",
    "                    sentence = sentence + s\n",
    "        elif pd.notna(row['protein']) and pd.notna(row['protein_Expression']):\n",
    "            s = f\"The sample {row['Sample']} has protein expression of {row['protein']} with expression level {row['protein_Expression']}\"\n",
    "            sentence = sentence + s\n",
    "            if pd.notna(row['transcript']):\n",
    "                s = f\" translated from transcript {row['transcript']}\"\n",
    "                sentence = sentence + s \n",
    "            if pd.notna(row['gene']):\n",
    "                s = f\" transcribed from gene {row['gene']}\"\n",
    "                sentence = sentence + s\n",
    "                if pd.notna(row['gene_Expression']):\n",
    "                    s = f\" with expression level {row['gene_Expression']}\"\n",
    "                    sentence = sentence + s\n",
    "            if pd.notna(row['mirna']): \n",
    "                s = f\" regulated by mirna {row['mirna']}\"\n",
    "                sentence = sentence + s\n",
    "                if pd.notna(row['mirna_Expression']):\n",
    "                    s = f\" with expression level {row['mirna_Expression']}\"\n",
    "                    sentence = sentence + s\n",
    "        elif pd.notna(row['mirna']) and pd.notna(row['mirna_Expression']):\n",
    "            s = f\"The sample {row['Sample']} has mirna expression of {row['mirna']} with expression level {row['mirna_Expression']}\"\n",
    "            sentence = sentence + s\n",
    "            if pd.notna(row['transcript']):\n",
    "                s = f\" that regulated the transcript {row['transcript']}\"\n",
    "                sentence = sentence + s \n",
    "            if pd.notna(row['gene']):\n",
    "                s = f\" transcribed from gene {row['gene']}\"\n",
    "                sentence = sentence + s\n",
    "                if pd.notna(row['gene_Expression']):\n",
    "                    s = f\" with expression level {row['gene_Expression']}\"\n",
    "                    sentence = sentence + s\n",
    "            if pd.notna(row['protein']):\n",
    "                s = f\" translated to protein {row['protein']}\" \n",
    "                sentence = sentence + s\n",
    "                if pd.notna(row['protein_Expression']):\n",
    "                    s = f\" with expression level {row['protein_Expression']}\"\n",
    "                    sentence = sentence + s\n",
    "        s = f\"the patient is {row['Gender']} with age {row['Age']} the cancer is {row['Type']}\"\n",
    "        sentence = sentence + s\n",
    "        return sentence\n",
    "\n",
    "            \n",
    "\n",
    "def remove_urls(cell):\n",
    "    if isinstance(cell, str):\n",
    "        urls_to_remove = [\n",
    "            'http://rdf.ebi.ac.uk/resource/sample/',\n",
    "            'http://rdf.ebi.ac.uk/resource/study/',\n",
    "            'http://rdf.ebi.ac.uk/resource/ensembl.miRNA/',\n",
    "            'http://rdf.ebi.ac.uk/resource/ensembl/',\n",
    "            'http://purl.uniprot.org/uniprot/',\n",
    "            'http://rdf.ebi.ac.uk/resource/ensembl.transcript/',\n",
    "            'http://rdf.ebi.ac.uk/resource/ensembl.protein/'\n",
    "        ]\n",
    "        for url in urls_to_remove:\n",
    "            cell = cell.replace(url, '')\n",
    "    return cell\n",
    "\n",
    "\n",
    "\n",
    "def query_to_df(sample_graph, study_graph, knowledge_graph, omic):\n",
    "    if omic == 'protein':\n",
    "        sparql_query_sample = \"\"\"\n",
    "        PREFIX sample: <http://rdf.ebi.ac.uk/resource/sample/>\n",
    "        PREFIX uniprot: <http://purl.uniprot.org/uniprot/>\n",
    "\n",
    "        SELECT ?sample ?protein ?expression\n",
    "        WHERE {\n",
    "            ?sample a <protein_expression> ;\n",
    "                    uniprot:hasProtein ?protein .\n",
    "\n",
    "            ?protein a uniprot:Protein ;\n",
    "                    sample:hasExpression ?expression .\n",
    "        }\n",
    "        \"\"\"\n",
    "    elif omic == 'gene':\n",
    "        sparql_query_sample = \"\"\"\n",
    "        PREFIX sample: <http://rdf.ebi.ac.uk/resource/sample/>\n",
    "        PREFIX ens: <http://rdf.ebi.ac.uk/resource/ensembl/>\n",
    "\n",
    "        SELECT ?sample ?gene ?expression\n",
    "        WHERE {\n",
    "            ?sample a <gene_expression> ;\n",
    "                    ens:hasGene ?gene .\n",
    "\n",
    "            ?gene a ens:Gene ;\n",
    "                    sample:hasExpression ?expression .\n",
    "        }\n",
    "        \"\"\"\n",
    "    elif omic == 'mirna':\n",
    "        sparql_query_sample = \"\"\"\n",
    "        PREFIX sample: <http://rdf.ebi.ac.uk/resource/sample/>\n",
    "        PREFIX mirna: <http://rdf.ebi.ac.uk/resource/ensembl.miRNA/>\n",
    "\n",
    "        SELECT ?sample ?mirna ?expression\n",
    "        WHERE {\n",
    "            ?sample a <mirna_expression> ;\n",
    "                    mirna:hasmiRNA ?mirna .\n",
    "\n",
    "            ?mirna a mirna:miRNA ;\n",
    "                    sample:hasExpression ?expression .\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "    sparql_query_study = \"\"\"\n",
    "            PREFIX sample: <http://rdf.ebi.ac.uk/resource/sample/>\n",
    "            PREFIX study: <http://rdf.ebi.ac.uk/resource/study/>\n",
    "            SELECT ?study ?sample ?age ?gender ?type\n",
    "            WHERE {\n",
    "            ?study a study:Study .\n",
    "            ?study study:hasSample ?sample .\n",
    "            ?sample sample:hasAge ?age .\n",
    "            ?sample sample:isGender ?gender .\n",
    "            ?sample sample:isType ?type .\n",
    "            }\n",
    "            \"\"\"\n",
    "    sparql_query_kg = \"\"\"PREFIX ens: <http://rdf.ebi.ac.uk/resource/ensembl/>\n",
    "            PREFIX protein: <http://rdf.ebi.ac.uk/resource/ensembl.protein/>\n",
    "            PREFIX transcript: <http://rdf.ebi.ac.uk/resource/ensembl.transcript/>\n",
    "            PREFIX uniprot: <http://purl.uniprot.org/uniprot/>\n",
    "            PREFIX mirna: <http://rdf.ebi.ac.uk/resource/ensembl.miRNA/>\n",
    "\n",
    "            SELECT ?gene ?transcript ?ensprotein ?uniprot ?mirna\n",
    "            WHERE {\n",
    "              ?mirna  mirna:regulates ?transcript .\n",
    "              ?gene ens:hasTranscript ?transcript .\n",
    "              ?transcript ens:hasProtein ?ensprotein .\n",
    "              ?ensprotein protein:isEquivalentTo ?uniprot.\n",
    "            }\"\"\"\n",
    "    # Execute SPARQL query\n",
    "    sample = sample_graph.query(sparql_query_sample)\n",
    "    columns = [\"Sample\", omic, omic+\"_Expression\"]\n",
    "    data = [(result[\"sample\"], result[omic], result[\"expression\"]) for result in sample]\n",
    "    df_sample = pd.DataFrame(data, columns=columns)\n",
    "    # Execute SPARQL query\n",
    "    study = study_graph.query(sparql_query_study)\n",
    "    columns = [\"Study\",\"Sample\", \"Age\", \"Gender\", \"Type\"]\n",
    "    data = [(result[\"study\"], result[\"sample\"], result[\"age\"], result[\"gender\"], result[\"type\"]) for result in study]\n",
    "    print(data)\n",
    "    df_study = pd.DataFrame(data, columns=columns)\n",
    "    # Execute SPARQL query\n",
    "    kg = knowledge_graph.query(sparql_query_kg)\n",
    "    columns = [\"gene\",\"transcript\", \"ens_protein\", \"protein\", \"mirna\"]\n",
    "    data = [(result[\"gene\"], result[\"transcript\"], result[\"ensprotein\"], result[\"uniprot\"], result[\"mirna\"]) for result in kg]\n",
    "    df_kg = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    merged_df_sample_kg = pd.merge(df_sample, df_kg, on=omic, how='left')\n",
    "    merged_study = pd.merge(merged_df_sample_kg, df_study, on='Sample', how='left')\n",
    "    merged_df_sample_kg = merged_df_sample_kg.map(remove_urls)\n",
    "    merged_study = merged_study.map(remove_urls)\n",
    "    return merged_df_sample_kg, merged_study\n",
    "\n",
    "\n",
    "def query_to_df(sample_graph, study_graph, omic):\n",
    "    if omic == 'protein':\n",
    "        sparql_query_sample = \"\"\"\n",
    "        PREFIX sample: <http://rdf.ebi.ac.uk/resource/sample/>\n",
    "        PREFIX uniprot: <http://purl.uniprot.org/uniprot/>\n",
    "\n",
    "        SELECT ?sample ?protein ?expression\n",
    "        WHERE {\n",
    "            ?sample a <protein_expression> ;\n",
    "                    uniprot:hasProtein ?protein .\n",
    "\n",
    "            ?protein a uniprot:Protein ;\n",
    "                    sample:hasExpression ?expression .\n",
    "        }\n",
    "        \"\"\"\n",
    "    elif omic == 'gene':\n",
    "        sparql_query_sample = \"\"\"\n",
    "        PREFIX sample: <http://rdf.ebi.ac.uk/resource/sample/>\n",
    "        PREFIX ens: <http://rdf.ebi.ac.uk/resource/ensembl/>\n",
    "\n",
    "        SELECT ?sample ?gene ?expression\n",
    "        WHERE {\n",
    "            ?sample a <gene_expression> ;\n",
    "                    ens:hasGene ?gene .\n",
    "\n",
    "            ?gene a ens:Gene ;\n",
    "                    sample:hasExpression ?expression .\n",
    "        }\n",
    "        \"\"\"\n",
    "    elif omic == 'mirna':\n",
    "        sparql_query_sample = \"\"\"\n",
    "        PREFIX sample: <http://rdf.ebi.ac.uk/resource/sample/>\n",
    "        PREFIX mirna: <http://rdf.ebi.ac.uk/resource/ensembl.miRNA/>\n",
    "\n",
    "        SELECT ?sample ?mirna ?expression\n",
    "        WHERE {\n",
    "            ?sample a <mirna_expression> ;\n",
    "                    mirna:hasmiRNA ?mirna .\n",
    "\n",
    "            ?mirna a mirna:miRNA ;\n",
    "                    sample:hasExpression ?expression .\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "    sparql_query_study = \"\"\"\n",
    "            PREFIX sample: <http://rdf.ebi.ac.uk/resource/sample/>\n",
    "            PREFIX study: <http://rdf.ebi.ac.uk/resource/study/>\n",
    "            SELECT ?study ?sample ?age ?gender ?type\n",
    "            WHERE {\n",
    "            ?study a study:Study .\n",
    "            ?study study:hasSample ?sample .\n",
    "            ?sample sample:hasAge ?age .\n",
    "            ?sample sample:isGender ?gender .\n",
    "            ?sample sample:isType ?type .\n",
    "            }\n",
    "            \"\"\"\n",
    "    sparql_query_kg = \"\"\"PREFIX ens: <http://rdf.ebi.ac.uk/resource/ensembl/>\n",
    "            PREFIX protein: <http://rdf.ebi.ac.uk/resource/ensembl.protein/>\n",
    "            PREFIX transcript: <http://rdf.ebi.ac.uk/resource/ensembl.transcript/>\n",
    "            PREFIX uniprot: <http://purl.uniprot.org/uniprot/>\n",
    "            PREFIX mirna: <http://rdf.ebi.ac.uk/resource/ensembl.miRNA/>\n",
    "\n",
    "            SELECT ?gene ?transcript ?ensprotein ?uniprot ?mirna\n",
    "            WHERE {\n",
    "              ?mirna  mirna:regulates ?transcript .\n",
    "              ?gene ens:hasTranscript ?transcript .\n",
    "              ?transcript ens:hasProtein ?ensprotein .\n",
    "              ?ensprotein protein:isEquivalentTo ?uniprot.\n",
    "            }\"\"\"\n",
    "    \n",
    "    \n",
    "    # Execute SPARQL query\n",
    "    sample = sample_graph.query(sparql_query_sample)\n",
    "    columns = [\"Sample\", omic, omic+\"_Expression\"]\n",
    "    data = [(result[\"sample\"], result[omic], result[\"expression\"]) for result in sample]\n",
    "    df_sample = pd.DataFrame(data, columns=columns)\n",
    "    # Execute SPARQL query\n",
    "    study = study_graph.query(sparql_query_study)\n",
    "    columns = [\"Study\",\"Sample\", \"Age\", \"Gender\", \"Type\"]\n",
    "    data = [(result[\"study\"], result[\"sample\"], result[\"age\"], result[\"gender\"], result[\"type\"]) for result in study]\n",
    "    df_study = pd.DataFrame(data, columns=columns)   \n",
    "    \n",
    "    merged_study_sample = pd.merge(df_sample, df_study, on='Sample', how='left') \n",
    "    merged_study_sample = merged_study_sample.map(remove_urls)\n",
    "    \n",
    "    if omic == 'gene':\n",
    "        merged_study_sample[omic]=merged_study_sample[omic].apply(gene_mod)\n",
    "\n",
    "    return merged_study_sample\n",
    "\n",
    "def split_dict(d, n):\n",
    "    \"\"\"\n",
    "    Split a dictionary into n smaller dictionaries.\n",
    "\n",
    "    Parameters:\n",
    "    - d (dict): The dictionary to be split.\n",
    "    - n (int): The number of smaller dictionaries to split the original dictionary into.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of smaller dictionaries.\n",
    "    \"\"\"\n",
    "    if n <= 0:\n",
    "        raise ValueError(\"Number of splits (n) must be greater than 0.\")\n",
    "    if len(d) < n:\n",
    "        raise ValueError(\"Number of splits (n) cannot exceed the length of the dictionary.\")\n",
    "    split_size = len(d) // n\n",
    "    smaller_dicts = []\n",
    "    start_idx = 0\n",
    "    for i in range(n):\n",
    "        end_idx = start_idx + split_size\n",
    "        smaller_dict = dict(list(d.items())[start_idx:end_idx])\n",
    "        smaller_dicts.append(smaller_dict)\n",
    "        start_idx = end_idx\n",
    "    if start_idx < len(d):\n",
    "        last_smaller_dict = dict(list(d.items())[start_idx:])\n",
    "        smaller_dicts[-1].update(last_smaller_dict)\n",
    "\n",
    "    return smaller_dicts\n",
    "\n",
    "def create_study_df(graph, omic):\n",
    "    if omic == 'protein':\n",
    "        sparql_query_sample = \"\"\"\n",
    "        PREFIX sample: <http://rdf.ebi.ac.uk/resource/sample/>\n",
    "        PREFIX uniprot: <http://purl.uniprot.org/uniprot/>\n",
    "\n",
    "        SELECT ?sample ?protein ?expression\n",
    "        WHERE {\n",
    "            ?sample a <protein_expression> ;\n",
    "                    uniprot:hasProtein ?protein .\n",
    "\n",
    "            ?protein a uniprot:Protein ;\n",
    "                    sample:hasExpression ?expression .\n",
    "        }\n",
    "        \"\"\"\n",
    "    elif omic == 'gene':\n",
    "        sparql_query_sample = \"\"\"\n",
    "        PREFIX sample: <http://rdf.ebi.ac.uk/resource/sample/>\n",
    "        PREFIX ens: <http://rdf.ebi.ac.uk/resource/ensembl/>\n",
    "\n",
    "        SELECT ?sample ?gene ?expression\n",
    "        WHERE {\n",
    "            ?sample a <gene_expression> ;\n",
    "                    ens:hasGene ?gene .\n",
    "\n",
    "            ?gene a ens:Gene ;\n",
    "                    sample:hasExpression ?expression .\n",
    "        }\n",
    "        \"\"\"\n",
    "    elif omic == 'mirna':\n",
    "        sparql_query_sample = \"\"\"\n",
    "        PREFIX sample: <http://rdf.ebi.ac.uk/resource/sample/>\n",
    "        PREFIX mirna: <http://rdf.ebi.ac.uk/resource/ensembl.miRNA/>\n",
    "\n",
    "        SELECT ?sample ?mirna ?expression\n",
    "        WHERE {\n",
    "            ?sample a <mirna_expression> ;\n",
    "                    mirna:hasmiRNA ?mirna .\n",
    "\n",
    "            ?mirna a mirna:miRNA ;\n",
    "                    sample:hasExpression ?expression .\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "    sam_study=pd.DataFrame()\n",
    "    for filename, sample_graph in graph.items():\n",
    "        sample = sample_graph.query(sparql_query_sample)\n",
    "        columns = [\"Sample\", omic, omic+\"_Expression\"]\n",
    "        data = [(result[\"sample\"], result[omic], result[\"expression\"]) for result in sample]\n",
    "        df_sample = pd.DataFrame(data, columns=columns)\n",
    "        sam_study = pd.concat([sam_study, df_sample], ignore_index=True)\n",
    "    sam_study = sam_study.map(remove_urls)\n",
    "    return sam_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f57a366-f3ea-4607-872f-e085cff1c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease = 'TCGA-BRCA'\n",
    "path= '/home/castilmg/multiomics/'\n",
    "prot_DB = pd.read_csv(path+'/TCGA_antibodies_descriptions.gencode.v36_2.tsv',sep='\\t')\n",
    "\n",
    "merged_df = pd.read_csv(path+'/merged_meta_df.csv')\n",
    "\n",
    "folder_path='/encrypted/e3008/Yang_tcga/tcga/'\n",
    "extension_to_read = '.tsv'  # Specify the extension you want to read, or set to None\n",
    "\n",
    "# PROTEINS\n",
    "omic = 'protein'\n",
    "prot_dic=iterate_and_read_files(folder_path, omic, disease, extension_to_read)\n",
    "prot_graph=create_rdf_graph_dict(prot_dic, merged_df, prot_DB)\n",
    "with open(f\"{path}/prot_graph_{disease}.pkl\", 'wb') as file:\n",
    "    pickle.dump(prot_graph, file)\n",
    "print(\"done proteins\")\n",
    "\n",
    "# GENES\n",
    "omic = 'gene'\n",
    "trans=iterate_and_read_files(folder_path, omic, disease, extension_to_read)\n",
    "trans_graph=create_rdf_graph_dict(trans, merged_df, prot_DB)\n",
    "with open(f\"{path}/trans_graph_{disease}.pkl\", 'wb') as file:\n",
    "    pickle.dump(trans_graph, file)\n",
    "print(f\"done transcripts\") \n",
    "\n",
    "# miRNAs\n",
    "omic = 'mirna'\n",
    "extension_to_read = 'mirnas.quantification.txt'\n",
    "miRNAs=iterate_and_read_files(folder_path, omic, disease, extension_to_read)\n",
    "miRNA_graph=create_rdf_graph_dict(miRNAs, merged_df, prot_DB)\n",
    "with open(f\"{path}/miRNA_graph_{disease}.pkl\", 'wb') as file:\n",
    "    pickle.dump(miRNA_graph, file)\n",
    "print(\"done mirnas\")\n",
    "\n",
    "# Multiomics\n",
    "with open(f\"{path}/trans_graph_{disease}.pkl\", 'rb') as file:\n",
    "    trans_graph = pickle.load(file)\n",
    "with open(f\"{path}/prot_graph_{disease}.pkl\", 'rb') as file:\n",
    "    prot_graph = pickle.load(file)\n",
    "with open(f\"{path}/miRNA_graph_{disease}.pkl\", 'rb') as file:\n",
    "    miRNA_graph = pickle.load(file)\n",
    "multiomics_graph_dic = {**trans_graph, **prot_graph, **miRNA_graph}\n",
    "multiomics_study_graph=create_rdf_graph_study(multiomics_graph_dic, meta, patient_df, disease)\n",
    "multiomics_study_graph.serialize(destination=f'{path}/output_study_{disease}.ttl', format='turtle')\n",
    "with open(f\"{path}/multiomics_graph_dic_{disease}.pkl\", 'wb') as file:\n",
    "    pickle.dump(multiomics_graph_dic, file)    \n",
    "print(\"done Multiomics\")\n",
    "\n",
    "multiomics_study_graph = Graph()\n",
    "multiomics_study_graph.parse(f\"{path}/output_study_{disease}.ttl\", format='turtle')\n",
    "\n",
    "# Study\n",
    "with open(f\"{path}/multiomics_graph_dic_{disease}.pkl\", 'rb') as file:\n",
    "    multiomics_graph_dic = pickle.load(file)\n",
    "\n",
    "multiomics_study_graph=create_rdf_graph_study(multiomics_graph_dic, meta, patient_df, disease)\n",
    "multiomics_study_graph.serialize(destination=f'{path}/output_study_{disease}_1.ttl', format='turtle')\n",
    "print(\"Done Study Graph\")\n",
    "\n",
    "#Integrate miRNAs to the Knowledge graph\n",
    "knowledge_graph = Graph()\n",
    "knowledge_graph.parse(path+'/Kownlege_graph.ttl', format='turtle')\n",
    "\n",
    "miRNA_DB = pd.read_csv(path+'/miRTarBase.csv')\n",
    "miRNA_DB.loc[:, 'miRNA'] = convert_miRNA_list(miRNA_DB['miRNA'])\n",
    "miRNA_DB.rename(columns={'ENSEMBL':'gene','Target Gene':'SYMBOL'}, inplace=True)\n",
    "miRNA_DB = miRNA_DB[['miRNA','gene']]\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "df_kg = kg.query_to_pandas(q)\n",
    "df_kg.columns=['protein','transcript','ensprotein', 'gene']\n",
    "\n",
    "multiomics_study_graph = Graph()\n",
    "multiomics_study_graph.parse(f\"{path}/output_study_{disease}.ttl\", format='turtle')\n",
    "\n",
    "df_kg2 = Knowledge_mirna_csv(df_kg,miRNA_DB)\n",
    "df_kg2=df_kg2.map(remove_urls)\n",
    "\n",
    "# Tranform Graph to Dataframes \n",
    "# PROTEIN\n",
    "with open(f\"{path}/prot_graph_{disease}.pkl\", 'rb') as file:\n",
    "    prot_graph = pickle.load(file)\n",
    "omic = 'protein'\n",
    "protein_sam_study = create_study_df(prot_graph, omic)\n",
    "# GENES\n",
    "with open(f\"{path}/trans_graph_{disease}.pkl\", 'rb') as file:\n",
    "    trans_graph = pickle.load(file)\n",
    "omic = 'gene'\n",
    "gene_sam_study = create_study_df(trans_graph, omic)\n",
    "gene_sam_study['gene'] = gene_sam_study['gene'].apply(gene_mod)\n",
    "# miRNA\n",
    "with open(f\"{path}/miRNA_graph_{disease}.pkl\", 'rb') as file:\n",
    "    miRNA_graph = pickle.load(file)\n",
    "omic = 'mirna'\n",
    "mirna_sam_study = create_study_df(miRNA_graph, omic)\n",
    "\n",
    "# Merge individual sample information with Knowledge graph\n",
    "protein_df = pd.merge(protein_sam_study, df_kg, on='protein', how='outer')\n",
    "gene_df = pd.merge(gene_sam_study, protein_df, on=['Sample','gene'], how='inner')\n",
    "multiomics_df = pd.merge(mirna_sam_study, gene_df, on=['mirna','Sample'], how='outer')\n",
    "\n",
    "# Query Study Graph\n",
    "sparql_query_study = \"\"\"\n",
    "    PREFIX sample: <http://rdf.ebi.ac.uk/resource/sample/>\n",
    "    PREFIX study: <http://rdf.ebi.ac.uk/resource/study/>\n",
    "    SELECT ?study ?sample ?age ?gender ?type\n",
    "    WHERE {\n",
    "    ?study a study:Study .\n",
    "    ?study study:hasSample ?sample .\n",
    "    ?sample sample:hasAge ?age .\n",
    "    ?sample sample:isGender ?gender .\n",
    "    ?sample sample:isType ?type .\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "study = multiomics_study_graph.query(sparql_query_study)\n",
    "# Organize the study graph query results in a Dataframe\n",
    "columns = [\"Study\",\"Sample\", \"Age\", \"Gender\", \"Type\"]\n",
    "data = [(result[\"study\"], result[\"sample\"], result[\"age\"], result[\"gender\"], result[\"type\"]) for result in study]\n",
    "df_study = pd.DataFrame(data, columns=columns)\n",
    "df_study = df_study.map(remove_urls)\n",
    "\n",
    "# Merge multiomics dataframe and the Study dataframe\n",
    "merged_multiomics_study = pd.merge(multiomics_df, df_study, on='Sample', how='left')\n",
    "\n",
    "#Standardize the Omics\n",
    "columns_to_standardize = ['mirna_Expression', 'gene_Expression', 'protein_Expression']\n",
    "merged_multiomics_study['mirna_Expression']=(merged_multiomics_study['mirna_Expression']-merged_multiomics_study['mirna_Expression'].mean())/(merged_multiomics_study['mirna_Expression'].std())#Standardize\n",
    "merged_multiomics_study['gene_Expression']=(merged_multiomics_study['gene_Expression']-merged_multiomics_study['gene_Expression'].mean())/(merged_multiomics_study['gene_Expression'].std())#Standardize\n",
    "merged_multiomics_study['protein_Expression']=(merged_multiomics_study['protein_Expression']-merged_multiomics_study['protein_Expression'].mean())/(merged_multiomics_study['protein_Expression'].std())#Standardize\n",
    "\n",
    "omic='multi'\n",
    "merged_multiomics_study['sentence'] = merged_multiomics_study.apply(create_sentence, axis=1, args=(omic,))\n",
    "merged_multiomics_study.to_csv(f\"{path}/multiomics_study_df_{disease}.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
